{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da88f96",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Imports\" data-toc-modified-id=\"Step-1:-Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Step 1: Imports</a></span></li><li><span><a href=\"#Step-2:-Config-+-helpers\" data-toc-modified-id=\"Step-2:-Config-+-helpers-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Step 2: Config + helpers</a></span></li><li><span><a href=\"#Step-3-IMPORTANT:-confirm-page-2-is-different-from-page-1\" data-toc-modified-id=\"Step-3-IMPORTANT:-confirm-page-2-is-different-from-page-1-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Step 3 IMPORTANT: confirm page 2 is different from page 1</a></span></li><li><span><a href=\"#Step-4-Extract-rows-from-HTML\" data-toc-modified-id=\"Step-4-Extract-rows-from-HTML-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Step 4 Extract rows from HTML</a></span></li><li><span><a href=\"#Step-5--Scrape-pages-1–40\" data-toc-modified-id=\"Step-5--Scrape-pages-1–40-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Step 5  Scrape pages 1–40</a></span></li><li><span><a href=\"#Step-6:-Save-to-CSV\" data-toc-modified-id=\"Step-6:-Save-to-CSV-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Step 6: Save to CSV</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87aed325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanu\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab154f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ------------------------ --------------- 3/5 [certifi]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2026.1.4 charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 urllib3-2.6.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ae3322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests version: 2.32.5\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "print(\"requests version:\", requests.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165319f8",
   "metadata": {},
   "source": [
    "## Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c61337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c688ab",
   "metadata": {},
   "source": [
    "## Step 2: Config + helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3f3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.rightmove.co.uk/house-prices/sk8.html\"\n",
    "TOTAL_PAGES = 40\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-GB,en;q=0.9\",\n",
    "}\n",
    "\n",
    "def polite_sleep():\n",
    "    time.sleep(random.uniform(1.0, 2.0))\n",
    "\n",
    "def page_url(n: int) -> str:\n",
    "    return BASE_URL if n == 1 else f\"{BASE_URL}?pageNumber={n}\"\n",
    "\n",
    "def fetch_html(session: requests.Session, url: str) -> str:\n",
    "    r = session.get(url, headers=HEADERS, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af4ae5",
   "metadata": {},
   "source": [
    "## Step 3 IMPORTANT: confirm page 2 is different from page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d87bda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different pages? True\n"
     ]
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "html1 = fetch_html(session, page_url(1))\n",
    "html2 = fetch_html(session, page_url(2))\n",
    "\n",
    "h1 = hashlib.md5(html1.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "h2 = hashlib.md5(html2.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "print(\"Different pages?\", h1 != h2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35b47b",
   "metadata": {},
   "source": [
    "## Step 4 Extract rows from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63872854",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTCODE_RE = re.compile(r\"\\b([A-Z]{1,2}\\d{1,2}[A-Z]?\\s*\\d[A-Z]{2})\\b\", re.I)\n",
    "PRICE_RE = re.compile(r\"£\\s?[\\d,]+\")\n",
    "DATE_RE  = re.compile(r\"\\b\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4}\\b\")\n",
    "\n",
    "BEDS_TENURE_RE = re.compile(r\"\\b(\\d{1,2})\\b\\s*(Freehold|Leasehold)\\b\", re.I)\n",
    "\n",
    "PROPERTY_TYPES = [\n",
    "    \"Detached\", \"Semi-Detached\", \"Terraced\", \"End Terrace\",\n",
    "    \"Flat\", \"Maisonette\", \"Bungalow\", \"Cottage\", \"Town House\"\n",
    "]\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
    "\n",
    "def split_address_postcode(full: str):\n",
    "    m = POSTCODE_RE.search(full or \"\")\n",
    "    if not m:\n",
    "        return norm(full), None\n",
    "    pc = re.sub(r\"\\s+\", \" \", m.group(1).upper()).strip()\n",
    "    addr = (full[:m.start()] + full[m.end():]).strip(\" ,\")\n",
    "    return norm(addr), pc\n",
    "\n",
    "def parse_property_type(text: str):\n",
    "    for t in PROPERTY_TYPES:\n",
    "        if re.search(rf\"\\b{re.escape(t)}\\b\", text, re.I):\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "def parse_tenure(text: str):\n",
    "    if re.search(r\"\\bFreehold\\b\", text, re.I):\n",
    "        return \"Freehold\"\n",
    "    if re.search(r\"\\bLeasehold\\b\", text, re.I):\n",
    "        return \"Leasehold\"\n",
    "    return None\n",
    "\n",
    "def extract_rows_from_html(html: str):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    rows = []\n",
    "\n",
    "    blocks = soup.find_all([\"a\", \"article\", \"li\", \"div\", \"section\"])\n",
    "\n",
    "    for b in blocks:\n",
    "        text = norm(b.get_text(\" \", strip=True))\n",
    "        if not text:\n",
    "            continue\n",
    "        if not POSTCODE_RE.search(text):\n",
    "            continue\n",
    "        if not PRICE_RE.search(text):\n",
    "            continue\n",
    "        if not re.search(r\"\\bFreehold\\b|\\bLeasehold\\b\", text, re.I):\n",
    "            continue\n",
    "\n",
    "        # address window around postcode\n",
    "        mpc = POSTCODE_RE.search(text)\n",
    "        start = max(0, mpc.start() - 200)\n",
    "        window = text[start:mpc.end() + 30]\n",
    "\n",
    "        maddr = re.search(r\"\\d{1,4}\\s*,[^£]{0,260}\", window)\n",
    "        if not maddr:\n",
    "            continue\n",
    "\n",
    "        addr_line = norm(maddr.group(0)).strip(\" ,\")\n",
    "        address, postcode = split_address_postcode(addr_line)\n",
    "\n",
    "        beds, tenure = None, None\n",
    "        mt = BEDS_TENURE_RE.search(text)\n",
    "        if mt:\n",
    "            beds = int(mt.group(1))\n",
    "            tenure = mt.group(2).capitalize()\n",
    "        else:\n",
    "            tenure = parse_tenure(text)\n",
    "\n",
    "        prop_type = parse_property_type(text)\n",
    "\n",
    "        d = DATE_RE.search(text)\n",
    "        p = PRICE_RE.search(text)\n",
    "        if not d or not p:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"address\": address,\n",
    "            \"postcode\": postcode,\n",
    "            \"property_type\": prop_type,\n",
    "            \"bedrooms\": beds,\n",
    "            \"tenure\": tenure,\n",
    "            \"last_sold_date\": d.group(0),\n",
    "            \"last_sold_price\": p.group(0),\n",
    "        })\n",
    "\n",
    "    # dedupe\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        key = (r[\"address\"], r[\"postcode\"], r[\"last_sold_date\"], r[\"last_sold_price\"])\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(r)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbec95",
   "metadata": {},
   "source": [
    "## Step 5  Scrape pages 1–40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36917937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1: https://www.rightmove.co.uk/house-prices/sk8.html\n",
      "  Rows found: 26\n",
      "Scraping page 2: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=2\n",
      "  Rows found: 25\n",
      "Scraping page 3: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=3\n",
      "  Rows found: 25\n",
      "Scraping page 4: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=4\n",
      "  Rows found: 26\n",
      "Scraping page 5: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=5\n",
      "  Rows found: 24\n",
      "Scraping page 6: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=6\n",
      "  Rows found: 25\n",
      "Scraping page 7: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=7\n",
      "  Rows found: 25\n",
      "Scraping page 8: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=8\n",
      "  Rows found: 25\n",
      "Scraping page 9: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=9\n",
      "  Rows found: 24\n",
      "Scraping page 10: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=10\n",
      "  Rows found: 24\n",
      "Scraping page 11: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=11\n",
      "  Rows found: 26\n",
      "Scraping page 12: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=12\n",
      "  Rows found: 25\n",
      "Scraping page 13: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=13\n",
      "  Rows found: 26\n",
      "Scraping page 14: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=14\n",
      "  Rows found: 24\n",
      "Scraping page 15: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=15\n",
      "  Rows found: 25\n",
      "Scraping page 16: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=16\n",
      "  Rows found: 26\n",
      "Scraping page 17: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=17\n",
      "  Rows found: 26\n",
      "Scraping page 18: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=18\n",
      "  Rows found: 25\n",
      "Scraping page 19: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=19\n",
      "  Rows found: 25\n",
      "Scraping page 20: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=20\n",
      "  Rows found: 26\n",
      "Scraping page 21: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=21\n",
      "  Rows found: 26\n",
      "Scraping page 22: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=22\n",
      "  Rows found: 25\n",
      "Scraping page 23: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=23\n",
      "  Rows found: 26\n",
      "Scraping page 24: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=24\n",
      "  Rows found: 26\n",
      "Scraping page 25: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=25\n",
      "  Rows found: 26\n",
      "Scraping page 26: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=26\n",
      "  Rows found: 24\n",
      "Scraping page 27: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=27\n",
      "  Rows found: 22\n",
      "Scraping page 28: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=28\n",
      "  Rows found: 25\n",
      "Scraping page 29: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=29\n",
      "  Rows found: 25\n",
      "Scraping page 30: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=30\n",
      "  Rows found: 24\n",
      "Scraping page 31: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=31\n",
      "  Rows found: 23\n",
      "Scraping page 32: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=32\n",
      "  Rows found: 24\n",
      "Scraping page 33: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=33\n",
      "  Rows found: 26\n",
      "Scraping page 34: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=34\n",
      "  Rows found: 26\n",
      "Scraping page 35: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=35\n",
      "  Rows found: 26\n",
      "Scraping page 36: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=36\n",
      "  Rows found: 26\n",
      "Scraping page 37: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=37\n",
      "  Rows found: 25\n",
      "Scraping page 38: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=38\n",
      "  Rows found: 26\n",
      "Scraping page 39: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=39\n",
      "  Rows found: 26\n",
      "Scraping page 40: https://www.rightmove.co.uk/house-prices/sk8.html?pageNumber=40\n",
      "  Rows found: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1004, 7),\n",
       "                                              address postcode property_type  \\\n",
       " 0  19, Easton Drive, Cheadle 13 Semi-Detached 3 F...  SK8 2JD      Detached   \n",
       " 1  19, Easton Drive, Cheadle 13 Semi-Detached 3 F...  SK8 2JD      Detached   \n",
       " 2  105, East Avenue, Heald Green, Cheadle 10 Deta...  SK8 3BS      Detached   \n",
       " 3  3, Massie Street, Cheadle 15 Terraced 4 Freeho...  SK8 1BW      Terraced   \n",
       " 4  12, Adshall Road, Cheadle 14 Terraced 2 Freeho...  SK8 2JN      Terraced   \n",
       " \n",
       "    bedrooms     tenure last_sold_date last_sold_price  \n",
       " 0       3.0   Freehold    19 Dec 2025        £384,044  \n",
       " 1       3.0   Freehold    19 Dec 2025        £315,000  \n",
       " 2       3.0  Leasehold    17 Dec 2025        £427,450  \n",
       " 3       4.0   Freehold    12 Dec 2025        £287,500  \n",
       " 4       2.0   Freehold    12 Dec 2025        £210,000  )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "all_rows = []\n",
    "\n",
    "prev_hash = None\n",
    "\n",
    "for n in range(1, TOTAL_PAGES + 1):\n",
    "    url = page_url(n)\n",
    "    print(f\"Scraping page {n}: {url}\")\n",
    "\n",
    "    html = fetch_html(session, url)\n",
    "    h = hashlib.md5(html.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "    if prev_hash is not None and h == prev_hash:\n",
    "        print(\"  WARNING: Page HTML repeated. Stopping to avoid duplicates.\")\n",
    "        break\n",
    "    prev_hash = h\n",
    "\n",
    "    rows = extract_rows_from_html(html)\n",
    "    print(f\"  Rows found: {len(rows)}\")\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "    polite_sleep()\n",
    "\n",
    "df_raw = pd.DataFrame(all_rows)\n",
    "df_raw.shape, df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16140429",
   "metadata": {},
   "source": [
    "## Step 6: Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00973855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: rightmove_sk8_df_raw.csv (1004, 7)\n"
     ]
    }
   ],
   "source": [
    "df_raw.to_csv(\"rightmove_sk8_df_raw.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Saved: rightmove_sk8_df_raw.csv\", df_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed615f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (system)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
